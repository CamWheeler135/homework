{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f694fb1b",
   "metadata": {},
   "source": [
    "# Chapter 01 Fundamentals of Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc19a894",
   "metadata": {},
   "source": [
    "Where does machine learning start and end? What does it mean for a machine to learn something? In this chapter, we will clarify what machine learning is and why you may want to use it. \n",
    "\n",
    "Before looking at the whole world of machine learning, we will first look at a map and learn the main regions and the most notable landmarks. Supervised vs Unsupervised, online vs batch learning, instance based learning vs model based learning. We will then look at the work flow of a machine learning project, discuss the main challenges we will face and cover how to evaluate and fine tune our machine learning system.\n",
    "\n",
    "This chapter will introduce a lot of fundamental concepts that every data scientist should know by heart (so this chapter is important). It will be high level overview (there isn't much code in this chapter!) but we need to know this so so so so so well before moving on! SO LETS GO."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2427d83f",
   "metadata": {},
   "source": [
    "### What is Machine Learning? \n",
    "\n",
    "Machine learning is the science (and art) of programming computers to learn from data. \"Machine learning is the feild of study that gives computers the ability to learn without being explicity programmed.\" and \"A computer program is said to learn from experience E with respect to some task T and some performance measure P, if it's performance on T, measured by P impoves with experience. \n",
    "\n",
    "Examples that a computer uses to learn is called a training set. Each training example is called a training instance, or sample. \n",
    "\n",
    "An example will be spam filters, where task T is to classify emails as spam or not spam, the experience E is the training data, and the performance P needs to be defined; for example, we can use the ratio of correctly classified emails. This particular perforamce measure is called accuracy and is commonly used in classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7dee5d",
   "metadata": {},
   "source": [
    "### Why Use Machine Learning? \n",
    "\n",
    "conside how you would write a spam filter using traditional programming techniques. \n",
    "\n",
    "1st we would consider what comes up in spam emails, we might look at phrases such as \"4U, credit card, free, won, amazing\" in the title, as these will often come up in spam emails a lot. Perhaps we would also notice a few patterns in the senders address, the the body of the email and other parts of the email. \n",
    "\n",
    "2nd we would write a detection algorithm for each of the patters that we have noticed, and our program would flag emails as spam if a number of these patterns are detected. \n",
    "\n",
    "3rd we would test our program and repeat the steps 1 and 2 until it is good enough to launch to the public. \n",
    "\n",
    "\n",
    "**Classic Programming**\n",
    "\n",
    "Study the problem, write the rules, evaluate ----> if bad, analyse errors and restart the process.\n",
    "\n",
    "Study the problem, write the rules, evalaute ----> if good, launch to the public.\n",
    "\n",
    "**Machine Learning**\n",
    "\n",
    "Study to problem, train a machine learning algorithm on data, evaluate ----> if bad, analyse errors and rester the process. \n",
    "\n",
    "study the problem, train a machine learning algorithm on data, evauluate ----> if good, launch to the public. \n",
    "\n",
    "\n",
    "Since the problem is difficult, our program will likely become a long list of complex rules that is hard to maintain. In contrast to this, a spam filter based on machine learning is rather simple, the computer will automatically learn what phrases are good predictors of spam by detecting unusually frequent patterns of words in the spam example training set compared to the non-spam emails. This program will be much shorter and easier to maintain and most likely more accurate then the human desinged program. \n",
    "\n",
    "\n",
    "It is also worth thinking that the earth is an ever changing envrionment, what happens if spammers learn that 4U causes emails to be placed into spam folder and start writing 'For U' in the email. If we had programmed the spam detection, we would have to go back to the program and rewrite the code to look for 'For U' instead. \n",
    "\n",
    "In contrast a machine learning algorithm, will automatically notice that 'For U' is appearing in spam emails flagged by users and adapt itself to flag them without our intervention.\n",
    "\n",
    "Another area where machine learning shines is for where problems are either too difficult for traditional programming or if there is no algorithm known. For example in speech recognition. Say we want to start simple and write a program that capabale of distinguishing the words one and two. We could notice that the word two starts with a higher pitch at the start (T), so we could hardcode the an algorithm to measure the sound intensity and use that to distinguish between one and two. But what happens when we want to distingush the words of english? what about languages of the world??????? It would be impossible. \n",
    "\n",
    "Finally machine learning can help humans learn as well! ML algorithms can be inspected to see what they have learned (although some algorithms can be hard to do this, I think we are talking about deep learning!). For instance, once a spam filteer has traoned one enough spam email, it be easily be inspected to reveal the list of words and combinations of words that it has learned to be the best predictors of spam emails. SOMETIMES, this will reveal correlations or new trends in the data that we havn't seen before, therefore leading to new understanding or better understanding of the problem. Applying ML techniques to dig into large amounts of data can help draw conclusions and discover patterns that were not immediately apparent to human analysts. \n",
    "\n",
    "---- To Summerise ---- \n",
    "\n",
    "- Problems for which existing solutions require complex programs, a lot of fine tuning or a long list of rules can benifit from machine learning by simplifying the code and perform better than traditional approaches. \n",
    "- Problems where traditional programming yeilds not so good solutions, the machine learning approach can perhaps find a solution. \n",
    "- Where the environment is fluctuating, a machine learning system can adapt to the new data.\n",
    "- Machine learning can yeild results from complex and large amounts of data that are not easily broken down and analysed by humans."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794ae771",
   "metadata": {},
   "source": [
    "### Examples of Applications\n",
    "\n",
    "Lets look at some concrete examples of Machine Learning tasks, along with the techniques that can tackle them. \n",
    "\n",
    "Analyzing images of products on a production line to automatically classify them ---> This is an image classification role and is typically performed using convolutional nerual networks. \n",
    "\n",
    "Detecting tumours in brain scans, this is called sematntic segmentation, where each pixel in the image is classified as we want to determine the exact location and shape of the tumour, typically using CNNs as well! \n",
    "\n",
    "Automatically classify news articles, this task is a natural language processing (NLP) task, more specifically a text classification which can be tackled by recurrent neural networks (RNNs), CNNs or Transformers. \n",
    "\n",
    "Automatically classify offensive or inapropriate comments on discussion forums, this is also a NLP task and uses the same stuff. \n",
    "\n",
    "Creating a chat bot or personal assistant, this inolves many NLP components, including natural language understanding (NLU) and question-answering modules. \n",
    "\n",
    "Forcasting your companys revenue next year based on many performance metrics. This is a regression task (predicting values) that can be tackled using any regression model such as Linear or Polynomial Regression Model, a regression SVM, a regression Random Forest, or an artifical neural network (ANN). If we want to take into account sequences of past performance we might want to use an RNN, CNN or Transformers \n",
    "\n",
    "Representing a complex, high dimensional dataset in a clear and insightful diagram. This is called data visualisation often involving dimensionality reduction technqiues \n",
    "\n",
    "Recccomending a product to a client may be interested in, based on past purchasing history. This is a recommender system. One approach is to feed past purchases of the client into an ANN and get it to output the most likely next purchase. This neural network would typically be trained on past sequences of purchases across all clinents (training set?)\n",
    "\n",
    "Building an intelligent bot for a game, this is often tackled using reinforcement learning, when is a branch of machine learning that trains agents to pick actions based on getting the most reward over time, within a given environment. The famous AlphaGo program that beat the world champion at the game Go was built using RL. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff4c020",
   "metadata": {},
   "source": [
    "### Types of Machine Learning\n",
    "\n",
    "There are so many types of machine learning it is worth classifying them into broad catagories. Based on certain criteria. \n",
    "\n",
    "- Whether or not they learn via human supervision (supervised, unsupervised, semi-supervised and reinforcement learning. \n",
    "\n",
    "- Whether or not they can learn incrementally on the fly (online learning vs batch learning).\n",
    "\n",
    "- Whether or not they work by comparing new data with known datapoints vs detecting patterns in the training data and building a predictive modle, much like scientists do. \n",
    "\n",
    "These criteria are NOT exclusive, for example a state of the art spam filter may learn on the fly using a deep neural network model that has been trained using examples of spam and normal (ham) emails; this makes it an online, model based supervised learning system. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d28b77a",
   "metadata": {},
   "source": [
    "### Supervised or Unsupervised Learning\n",
    "\n",
    "We can classify machine learning systems based on the amount and type of supervision they get when they are training. There are four major types, supervised, unsupervised, semi-supervised and reinforcement. \n",
    "\n",
    "\n",
    "**Supervised Learning**\n",
    "\n",
    "In supervised learning, the training set you feed into the algorithm includes the desired solutions (the answers) these are called 'labels'. The most typical type of supervised learning task is classification. The spam filter example is a good example of this: it is trained with labelled examples of what is spam and what isnt spam and it must learn to how to classify new emails. \n",
    "\n",
    "Another typical task is to predict target numeric value, such as the price of a car given a certain set of features (milage, brand, age etc) these are called 'predictors'. This sort of task is called regression (predict a value, given an input feature. There are usually multiple input features and soemtimes multiple output values) to train a system like this for the car we would need to give it many examples of cars, their features and their price!\n",
    "\n",
    "---- Note ----\n",
    "In machine learning an 'attribute' is a data type (e.g milage), while a 'feature' has several meanings depending on the context but generally means an attribute that is paried with its value (e.g milage = 13,000). Many people use the words attribute and feature interchangeably. \n",
    "\n",
    "Also note that some regression algorithms cna be used for classification as well. For example logistic regression is commonly used for classification as it can produe ce an output value that corresponds to the probabilty of belonging to a certain class (e.g 20% chance of bein spam) \n",
    "\n",
    "We will cover some important supervised learning algorithms \n",
    "\n",
    "- k-Nearest Neighbors\n",
    "- Linear Regression \n",
    "- Support Vector Machine \n",
    "- Decision Tress and Random Forests \n",
    "- Neural Networks (although some can be unsupervised such as autoencoders, some can be semi supervised such as deep belief networks) \n",
    "\n",
    "**Unsupervised Learning** \n",
    "\n",
    "In unsupervised learning, the training data is not labelled (unlabelled) and the system tries to learn without a teacher. \n",
    "\n",
    "Here are some of the most common unsupervised learning algorithms that are covered later in the book. \n",
    "\n",
    "**clustering**\n",
    "- K-means \n",
    "- DBSCAN\n",
    "- Hierarchial Cluster Analysis (HCA) \n",
    "\n",
    "**anomaly detection an novelty detection**\n",
    "- One-class SVM \n",
    "- Isolation Forest\n",
    "\n",
    "**Visulisation and Dimensionaltiy Reduction**\n",
    "- Principle Component Analysis (PCA)\n",
    "- Kernal PCA \n",
    "- Locally Linear Embedding (LLE) \n",
    "- t-Distributed Stochastic Neighbor Embedding (t-SNE)\n",
    "\n",
    "**Association Rule Learning** \n",
    "- Apriori \n",
    "- Eclat \n",
    "\n",
    "\n",
    "For example, lets say we have some information based on visitors to a blog, we can run a clustering algorithm that will group visitors into a group of similarities. But at no point do we tell the algorithm which group a visitor belongs too, the algorithm will find the connections without our help. For example the algorithm might notice 40% of our blog visitors are males who love comic books and will read our blog in the evening before bed, while 20% of our visitors young sci-fi lovers who read our blog on the weekend. If we use hierarchical clustering algorithm, it might subdivide those visitors into smaller groups. This can help us target specific audiences with our posts. \n",
    "\n",
    "Visualisation aglorithms are also great examples of unsupervised learning, we feed the algorithm complex high dimensional data and it will output 2D or 3D representation so that it can be easily plotted. These algorithms try to preserve the structure as much as it can (trying to keep separete clusters in the input space from overlapping) so that we can understand how the data is organised and perhaps identify unsuspected patterns. \n",
    "\n",
    "A related task is dimensionality reduction, in which the goal is to simplify the data without losing too much information. One way to do this is to merge several correlated features into one (what I am doing in my disso?). For example a cars milage might strongly correlate to its age, so the dimensionality reduction algorithm will merge them into one feature that represents the cars wear and tear!!! This is called feature extraction. It is often a good idea to feed our data into a dimensionality reduction algorithm before feeding it into another machine learning algorithm such as a supervised learning algorithm. It will run faster, take up less memory and could in some cases perform better. \n",
    "\n",
    "Another important unsupervised task is anomaly detection such as credit card spending, catching manufacturing defects or looking for defective data before feeding it into another machine learning algorithm. The system is shown mostly normal instances during training and it learns to recognise them, we then feed a new instance it can tell weather it looks like a normal instance or an anomaly. A similar task is vovelty detection, this requires we have a very clean dataset that doesn't have an examples of the data we are trying to detect. For example if we have pictures of dogs even if we have one Labrador the algorithm will not say Labrador is a novelty, on the other hand a anomaly detection algorithm might see that there is only 1 Labrador and then detect another Labrador as an anomaly in the data.\n",
    "\n",
    "Finally another common unsupervised learning task is assocation rule learning, in which the goal is to dig into really complext data and find relations between attributes. For example if we own a supermarket, would use an association rule algorithm to find corrections in the sales of our data and find that people who buy BBQ sauce and chips will also buy steak as well. \n",
    "\n",
    "\n",
    "**Semi Supervised Learning** \n",
    "\n",
    "Some algorithms deal with partially labelled data usually a lot of unlabelled data and some small amounts of labelled data, an example of this is the Google photos, where it groups people such as person A is in photo 1,3,7 and person B is in 4,6,2 based on their looks and will only take one label (us telling google who the person is) for google to go and find them in all of the other photos. Although in practice this doesn't work so well, sometimes we need to label a person a couple of times before google starts to get ahold of the photos properly. \n",
    "\n",
    "Most semi supervised learning algorithms are combinations of unsupervised and supervised algorithms, such as deep belief networks (DBP). Thesea are based on unsupervised components called restrited Boltzmnn Machines (RBMs) stacked on top of one another. RBMs are trainned sequentially in an unsupervised manner and then the fine tuning is done using supervised learning techniques. \n",
    "\n",
    "\n",
    "**Reinforcement Learning** \n",
    "\n",
    "\"This is a very different beast\" The learning system called an 'agent' in this context, can observe the environment, select and perform actions and get rewards based on those actions. It must then learn by itself what is the best stratgey called a 'policy' to get the most reward over time. A policy defines what action the agent should choose when it is in a certain situation. \n",
    "\n",
    "For example many robots implement Reinforcement learning algorithms to learn how to walk. DeepMinds AlphaGo program is a great reinforcement learning algorithm. It learned its policy by analysing millions of games, and then playing games against itself. Note that learning was turned off when playing the champion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
